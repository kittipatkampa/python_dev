{
 "metadata": {
  "name": "",
  "signature": "sha256:5710a81940c0ee09caeca71826d0a41b53b6b360b481e257cd17507b0f5e6d46"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Sklearn-pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I just copy and paste from the original: https://github.com/paulgb/sklearn-pandas"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This module provides a bridge between [`Scikit-Learn`](http://scikit-learn.org/stable/)'s machine learning methods and [`pandas`](http://pandas.pydata.org/)-style Data Frames.\n",
      "\n",
      "In particular, it provides:\n",
      "\n",
      "1. a way to map DataFrame columns to transformations, which are later recombined into features\n",
      "2. a way to cross-validate a pipeline that takes a pandas DataFrame as input."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Installation\n",
      "------------\n",
      "\n",
      "You can install ``sklearn-pandas`` with ``pip``:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pip install sklearn-pandas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tests\n",
      "-----\n",
      "\n",
      "The examples in this file double as basic sanity tests. To run them, use ``doctest``, which is included with python::"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# python -m doctest README.rst"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usage\n",
      "-----"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Import"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import what you need from the ``sklearn_pandas`` package. The choices are:\n",
      "\n",
      "* ``DataFrameMapper``, a class for mapping pandas data frame columns to different sklearn transformations\n",
      "* ``cross_val_score``, similar to `sklearn.cross_validation.cross_val_score` but working on pandas DataFrames\n",
      "\n",
      "For this demonstration, we will import both:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> from sklearn_pandas import DataFrameMapper, cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For these examples, we'll also use pandas, numpy, and sklearn:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> import pandas as pd\n",
      ">>> import numpy as np\n",
      ">>> import sklearn.preprocessing, sklearn.decomposition, \\\n",
      "...     sklearn.linear_model, sklearn.pipeline, sklearn.metrics"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load some Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Normally you'll read the data from a file, but for demonstration purposes I'll create a data frame from a Python dict:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> data = pd.DataFrame({'pet':      ['cat', 'dog', 'dog', 'fish', 'cat', 'dog', 'cat', 'fish'],\n",
      "...                      'children': [4., 6, 3, 3, 2, 3, 5, 4],\n",
      "...                      'salary':   [90, 24, 44, 27, 32, 59, 36, 27]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Transformation Mapping\n",
      "----------------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Map the Columns to Transformations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The mapper takes a list of pairs. The first is a column name from the pandas DataFrame (or a list of multiple columns, as we will see later). The second is an object which will perform the transformation which will be applied to that column::"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> mapper = DataFrameMapper([\n",
      "...     ('pet', sklearn.preprocessing.LabelBinarizer()),\n",
      "...     ('children', sklearn.preprocessing.StandardScaler())\n",
      "... ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Test the Transformation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use the ``fit_transform`` shortcut to both fit the model and see what transformed data looks like. In this and the other examples, output is rounded to two digits with ``np.round`` to account for rounding errors on different hardware:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> np.round(mapper.fit_transform(data), 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "array([[ 1.  ,  0.  ,  0.  ,  0.21],\n",
        "       [ 0.  ,  1.  ,  0.  ,  1.88],\n",
        "       [ 0.  ,  1.  ,  0.  , -0.63],\n",
        "       [ 0.  ,  0.  ,  1.  , -0.63],\n",
        "       [ 1.  ,  0.  ,  0.  , -1.46],\n",
        "       [ 0.  ,  1.  ,  0.  , -0.63],\n",
        "       [ 1.  ,  0.  ,  0.  ,  1.04],\n",
        "       [ 0.  ,  0.  ,  1.  ,  0.21]])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the first three columns are the output of the ``LabelBinarizer`` (corresponding to _cat_, _dog_, and _fish_ respectively) and the fourth column is the standardized value for the number of children. In general, the columns are ordered according to the order given when the ``DataFrameMapper`` is constructed.\n",
      "\n",
      "Now that the transformation is trained, we confirm that it works on new data::"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> sample = pd.DataFrame({'pet': ['cat'], 'children': [5.]})\n",
      ">>> np.round(mapper.transform(sample), 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([[ 1.,  0.,  0.,  5.]])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Transform Multiple Columns"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Transformations may require multiple input columns. In these cases, the column names can be specified in a list:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> mapper2 = DataFrameMapper([\n",
      "...     (['children', 'salary'], sklearn.decomposition.PCA(1))\n",
      "... ])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now running ``fit_transform`` will run PCA on the ``children`` and ``salary`` columns and return the first principal component::"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> np.round(mapper2.fit_transform(data), 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([[ 47.6],\n",
        "       [-18.4],\n",
        "       [  1.6],\n",
        "       [-15.4],\n",
        "       [-10.4],\n",
        "       [ 16.6],\n",
        "       [ -6.4],\n",
        "       [-15.4]])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cross-Validation\n",
      "----------------\n",
      "\n",
      "Now that we can combine features from pandas DataFrames, we may want to use cross-validation to see whether our model works. Scikit-learn provides features for cross-validation, but they expect numpy data structures and won't work with ``DataFrameMapper``.\n",
      "\n",
      "To get around this, sklearn-pandas provides a wrapper on sklearn's ``cross_val_score`` function which passes a pandas DataFrame to the estimator rather than a numpy array:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      ">>> pipe = sklearn.pipeline.Pipeline([\n",
      "...     ('featurize', mapper),\n",
      "...     ('lm', sklearn.linear_model.LinearRegression())])\n",
      ">>> np.round(cross_val_score(pipe, data, data.salary, 'r2'), 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "array([ -1.09,  -5.3 , -15.38])"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sklearn-pandas' ``cross_val_score`` function provides exactly the same interface as sklearn's function of the same name."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Credit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code for ``DataFrameMapper`` is based on code originally written by [Ben Hamner](https://github.com/benhamner)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}